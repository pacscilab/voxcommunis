{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cv_languages import LANGUAGES\n",
    "from cv_release_stats import STATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the iso639-3 language code table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the table of iso639 codes\n",
    "iso639 = pd.read_table('iso-639-3.tab', sep = '\\t')\n",
    "iso639 = iso639.drop(['Part2b', 'Part2t', 'Scope', 'Language_Type', 'Comment'], axis = 1).rename(columns = {'Ref_Name': 'name', 'Id': 'code_iso639-3'})\n",
    "iso639.rename(columns = {'Part1': 'code_iso639-1'}, inplace=True)\n",
    "print(iso639)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the information of Common Voice corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load info from Common Voice corpus\n",
    "cv_lang = pd.DataFrame.from_dict(LANGUAGES, orient = 'index')\n",
    "cv_log = pd.DataFrame.from_dict(STATS['locales'], orient = 'index')\n",
    "cv_log['validClips'] = cv_log.buckets.apply(pd.Series)['validated']\n",
    "cv_log = cv_log[['clips', 'validClips', 'totalHrs', 'validHrs']]\n",
    "cv_track = pd.concat([cv_lang, cv_log], join = 'inner', axis = 1)\n",
    "cv_track.rename(columns={0: \"name\"}, inplace = True)\n",
    "cv_track.index.name = 'code'\n",
    "\n",
    "cv_lang_code = cv_track['name'].reset_index()\n",
    "cv_lang_code[['code', 'code_cv_suffix']] = cv_lang_code.code.str.split('-', expand=True)\n",
    "cv_lang_code['code_cv_suffix'] = cv_lang_code['code_cv_suffix'].fillna('')\n",
    "\n",
    "cv_lang2 = cv_lang_code[cv_lang_code['code'].str.len() != 3]\n",
    "cv_lang2.set_index('code', inplace=True)\n",
    "cv_lang3 = cv_lang_code[cv_lang_code['code'].str.len() == 3]\n",
    "cv_lang3.set_index('code', inplace=True)\n",
    "print('Two-letter coded languages in Common Voice:')\n",
    "print(cv_lang2)\n",
    "print('\\n')\n",
    "print('Three-letter coded languages in Common Voice:')\n",
    "print(cv_lang3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the iso639-3 3-letter codes for languages in Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For languages in Common Voice that used a non-three-letter code:\n",
    "iso639_2 = iso639.rename(columns = {'code_iso639-1': 'code'})\n",
    "iso639_2.set_index('code', inplace=True)\n",
    "\n",
    "# Join it with iso639 table\n",
    "cv_res2 = iso639_2.join(cv_lang2, how = 'right', lsuffix = '_iso639-3', rsuffix = '_cv')\n",
    "cv_res2.reset_index(inplace=True)\n",
    "\n",
    "# Update the codes with iso639-3 codes\n",
    "cv_res2['code_update'] = cv_res2['code_iso639-3']\n",
    "\n",
    "cv_res2.drop(['code_iso639-3', 'code'], axis = 1, inplace=True)\n",
    "cv_res2.set_index('code_update', inplace=True)\n",
    "print('The updated language codes:')\n",
    "print(cv_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For languages in Common Voice that used a non-three-letter code:\n",
    "iso639_3 = iso639.rename(columns = {'code_iso639-3': 'code'})\n",
    "iso639_3.set_index('code', inplace=True)\n",
    "\n",
    "# Join it with iso639 table\n",
    "cv_res3 = iso639_3.join(cv_lang3, how = 'right', lsuffix = '_iso639-3', rsuffix = '_cv')\n",
    "cv_res3.reset_index(inplace=True)\n",
    "\n",
    "# Update the codes with iso639-3 codes\n",
    "cv_res3['code_update'] = cv_res3['code']\n",
    "cv_res3.drop(['code_iso639-1', 'code'], axis = 1, inplace=True)\n",
    "cv_res3.set_index('code_update', inplace=True)\n",
    "print('The updated language codes:')\n",
    "print(cv_res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the updated codes\n",
    "cv_res = pd.concat([cv_res2, cv_res3], axis=0)\n",
    "cv_res.rename(columns = {'name_cv': 'name'}, inplace=True)\n",
    "print(cv_res)\n",
    "del cv_res2, cv_res3, cv_lang2, cv_lang3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the language code in Common Voice\n",
    "cv_track.reset_index(inplace=True)\n",
    "cv_track.set_index('name', inplace=True)\n",
    "print(cv_track)\n",
    "\n",
    "cv_res.reset_index(inplace=True)\n",
    "cv_res.set_index('name',inplace=True)\n",
    "print(cv_res)\n",
    "\n",
    "cv_update = cv_track.join(cv_res, how = 'left')\n",
    "print(cv_update)\n",
    "\n",
    "del cv_track, cv_res, cv_lang, cv_lang_code, cv_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the iso639-3 codes for the languages in XPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load info from XPF corpus\n",
    "xpf_list = pd.read_table('xpf_langs-list.tsv')\n",
    "xpf_list = xpf_list[['code', 'name', 'compromised']]\n",
    "xpf_list['xpf'] = np.where(pd.isna(xpf_list['compromised']), 'yes', 'compromised')\n",
    "xpf_list.rename(columns={'name': 'name_xpf'}, inplace=True)\n",
    "xpf_list = xpf_list.drop(['compromised'], axis = 1)\n",
    "\n",
    "xpf_list2 = xpf_list[xpf_list['code'].str.len() != 3]\n",
    "xpf_list2.set_index('code', inplace=True)\n",
    "xpf_list3 = xpf_list[xpf_list['code'].str.len() == 3]\n",
    "xpf_list3.set_index('code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For languages in Common Voice that used a non-three-letter code:\n",
    "iso639_2 = iso639.rename(columns = {'code_iso639-1': 'code'})\n",
    "iso639_2 = iso639_2[pd.notna(iso639_2['code'])]\n",
    "iso639_2.set_index('code', inplace=True)\n",
    "\n",
    "# Join it with iso639 table\n",
    "xpf_res2 = iso639_2.join(xpf_list2, how = 'right', lsuffix = '_iso639-3', rsuffix = '_xpf')\n",
    "xpf_res2.reset_index(inplace=True)\n",
    "\n",
    "# Update the codes with iso639-3 codes\n",
    "xpf_res2.rename(columns = {'code_iso639-3': 'code_update'}, inplace=True)\n",
    "xpf_res2.set_index('code_update', inplace=True)\n",
    "xpf_res2.rename(columns = {'code': 'code_xpf'}, inplace=True)\n",
    "print('The updated language codes:')\n",
    "print(xpf_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For languages in Common Voice that used a three-letter code:\n",
    "iso639_3 = iso639.rename(columns = {'code_iso639-3': 'code'})\n",
    "iso639_3.set_index('code', inplace=True)\n",
    "\n",
    "# Join it with iso639 table\n",
    "xpf_res3 = iso639_3.join(xpf_list3, how = 'right', lsuffix = '_iso639-3', rsuffix = '_xpf')\n",
    "xpf_res3.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Update the codes with iso639-3 codes\n",
    "xpf_res3['code_update'] = xpf_res3['code']\n",
    "xpf_res3.rename(columns = {'code': 'code_xpf'}, inplace=True)\n",
    "xpf_res3.drop(['code_iso639-1'], axis = 1, inplace=True)\n",
    "xpf_res3.set_index('code_update', inplace=True)\n",
    "print('The updated language codes:')\n",
    "print(xpf_res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpf_res = pd.concat([xpf_res2, xpf_res3], axis = 0)\n",
    "xpf_res.drop('name', axis = 1, inplace=True)\n",
    "print(xpf_res)\n",
    "del xpf_res2, xpf_res3, xpf_list2, xpf_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load info from Epitran\n",
    "epi_list = pd.read_csv('epi_langs-list.csv')\n",
    "epi_list[['code', 'epi_ortho_typ']] = epi_list.Code.str.split('-', n=1, expand = True)\n",
    "epi_list.rename(columns = {'Code': 'code_epi'}, inplace=True)\n",
    "epi_list = epi_list.rename(columns={'Language (Script)' : 'name_epi'})\n",
    "epi_list = epi_list.set_index('code')\n",
    "epi_list['name_epi'] = epi_list.name_epi.str.replace(' \\(.+\\)', '', regex=True)\n",
    "epi_list['epitran'] = 'yes'\n",
    "epi_list = epi_list.drop('epi_ortho_typ', axis=1).drop_duplicates()\n",
    "\n",
    "epi_list.index.name = 'code_update'\n",
    "print(epi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_update.rename(columns={\"name\": \"name_cv\"}, inplace= True)\n",
    "xpf_res.rename(columns={\"name\": \"name_iso\"}, inplace= True)\n",
    "cv_update.reset_index(inplace=True)\n",
    "cv_update.set_index('code_update', inplace=True)\n",
    "xpf_res.reset_index(inplace=True)\n",
    "xpf_res.set_index('code_update', inplace=True)\n",
    "\n",
    "print(\"Epitran:\\n\", epi_list)\n",
    "print(\"\\nCommon Voice:\\n\", cv_update)\n",
    "print(\"\\nXPF:\\n\", xpf_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them\n",
    "vxc_info = cv_update.join(xpf_res, how = 'left')\n",
    "vxc_info.rename(columns = {'code': 'code_cv'}, inplace=True)\n",
    "vxc_info = vxc_info.join(epi_list, how = 'left')\n",
    "vxc_info.reset_index(inplace=True)\n",
    "vxc_info.drop(['code_update', 'code_cv_suffix'], axis = 1, inplace=True)\n",
    "vxc_info = vxc_info[['code_cv', 'name', 'name_iso639-3', 'name_xpf', 'name_epi', 'clips', 'validClips', 'totalHrs', 'validHrs', 'xpf', 'code_xpf', 'epitran', 'code_epi']]\n",
    "vxc_info.rename(columns={'name': 'name_cv'}, inplace=True)\n",
    "vxc_info['spkr_file'] = ''\n",
    "vxc_info['lexicon'] = ''\n",
    "vxc_info['acoustic_model'] = ''\n",
    "print(vxc_info)\n",
    "\n",
    "vxc_info.drop_duplicates(inplace=True)\n",
    "vxc_info.to_csv('/Users/miaozhang/Research/CorpusPhon/Scripts/vxc_lang_code_processing/VoxCommunis_Info.csv')\n",
    "\n",
    "del cv_update, epi_list, iso639, iso639_2, iso639_3, LANGUAGES, STATS, xpf_list, xpf_res, vxc_info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
